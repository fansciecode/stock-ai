#!/usr/bin/env python3
"""
IBCM AI Service
Real LLaMA-based AI with fine-tuning, vector search, and multimodal capabilities
"""

import os
import json
import logging
import asyncio
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

import torch
import numpy as np

def _get_current_season() -> str:
    """Get current season"""
    month = datetime.now().month
    if month in [12, 1, 2]:
        return 'winter'
    elif month in [3, 4, 5]:
        return 'spring'
    elif month in [6, 7, 8]:
        return 'summer'
    else:
        return 'fall'
from fastapi import FastAPI, HTTPException, Body, Depends
from fastapi.security import APIKeyHeader
from fastapi.middleware.cors import CORSMiddleware
import uvicorn

# Core AI libraries
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline
from sentence_transformers import SentenceTransformer
from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training
import faiss
from sklearn.metrics.pairwise import cosine_similarity

# Database
import pymongo
import redis

# Optional multimodal
try:
    from diffusers import StableDiffusionPipeline
    DIFFUSION_AVAILABLE = True
except ImportError:
    DIFFUSION_AVAILABLE = False

# Import agent system
from agents import AgentOrchestrator
from production_model_loader import load_trained_ibcm_model
from content_generation_engine import create_content_generator
from kafka_streaming_engine import create_kafka_streamer
from social_features import create_social_features_engine
from affiliate_system import create_affiliate_system

# Import new advanced modules
from ar_vr_integration import create_ar_vr_integration
from ip_management import create_ip_management
from advanced_analytics import create_advanced_analytics
from background_ingestion import create_background_ingestion
from feed_module import create_feed_module
from federated_learning import create_federated_learning
from cross_platform_integration import create_cross_platform_integration

# Import universal AI modules
from universal_web_trainer import create_universal_web_trainer
from universal_ai_agents import UniversalAgentOrchestrator, AnalysisResult

# Import real-time price exchange
from real_time_price_exchange import create_real_time_price_exchange

# Import spatio-temporal engine  
from spatio_temporal_engine import create_spatio_temporal_engine, UserContext

# Import input validation and text preprocessing
from input_validator import validate_user_input, validate_json_data, create_safe_llm_prompt
from text_preprocessor import preprocess_user_text, clean_and_format_for_llm

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuration
class Config:
    # API Configuration - All from environment
    API_HOST = os.getenv("AI_API_HOST", "0.0.0.0")
    API_PORT = int(os.getenv("AI_API_PORT", "8001"))
    API_KEY = os.getenv("API_KEY", "ibcm_ai_key_2024")
    
    # Database Configuration - All from environment
    MONGO_URI = os.getenv("MONGO_URI", "mongodb://admin:password123@localhost:27017/ibcm_ai?authSource=admin")
    DB_NAME = os.getenv("DB_NAME", "ibcm_ai")
    REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")
    
    # AI Models Configuration - All from environment
    LLAMA_MODEL = os.getenv("LLAMA_MODEL", "microsoft/DialoGPT-medium")
    EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "all-MiniLM-L6-v2")
    DEVICE = os.getenv("DEVICE", "mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu")
    
    # Backend Integration - All from environment
    BACKEND_API_URL = os.getenv("BACKEND_API_URL", "http://localhost:5001/api")
    
    # External Services - All from environment
    ELASTICSEARCH_URL = os.getenv("ELASTICSEARCH_URL", "http://localhost:9200")
    
    # Environment Settings
    ENVIRONMENT = os.getenv("ENVIRONMENT", "development")
    DEBUG = os.getenv("DEBUG", "true").lower() == "true"
    
    # Model parameters
    MAX_LENGTH = 512
    TEMPERATURE = 0.7
    TOP_K = 10

config = Config()

class IBCMAIEngine:
    """Core IBCM AI Engine with LLaMA, embeddings, and vector search"""
    
    def __init__(self):
        self.config = config  # Add config reference
        self.tokenizer = None
        self.model = None
        self.embedding_model = None
        self.faiss_index = None
        self.entity_embeddings = {}
        self.db = None
        self.redis_client = None
        self.agent_orchestrator = None
        self.ibcm_trained_model = None
        self.content_generator = None
        self.kafka_streamer = None
        self.social_engine = None
        self.affiliate_system = None
        self.initialized = False
        
    async def initialize(self):
        """Initialize AI engine"""
        try:
            logger.info("ðŸš€ Initializing IBCM AI Engine...")
            
            # Connect to databases
            await self._connect_databases()
            
            # Load LLaMA model
            await self._load_llama_model()
            
            # Load embedding model
            await self._load_embedding_model()
            
            # Build embeddings
            await self._build_embeddings()
            
            # Initialize IBCM trained model (the ACTUAL custom AI)
            logger.info("ðŸŽ¯ Loading IBCM Production Model...")
            self.ibcm_trained_model = await load_trained_ibcm_model(config.DEVICE)
            
            # Initialize advanced agent system
            logger.info("ðŸ¤– Initializing Advanced Agent System...")
            self.agent_orchestrator = AgentOrchestrator(self)
            
            # Initialize universal orchestrator with error handling
            try:
                self.universal_orchestrator = UniversalAgentOrchestrator(self)
                logger.info("âœ… Universal orchestrator initialized")
            except Exception as e:
                logger.error(f"âŒ Universal orchestrator failed: {e}")
                self.universal_orchestrator = None
            
            # Initialize universal web trainer
            try:
                self.universal_trainer = create_universal_web_trainer(config)
                logger.info("âœ… Universal trainer initialized")
            except Exception as e:
                logger.warning(f"Universal trainer not available: {e}")
                self.universal_trainer = None
            
            # Initialize real-time price exchange
            try:
                self.price_exchange = create_real_time_price_exchange(config)
                logger.info("âœ… Real-time price exchange initialized")
            except Exception as e:
                logger.warning(f"Price exchange not available: {e}")
                self.price_exchange = None
            
            # Initialize spatio-temporal engine (Your core vision!)
            try:
                self.spatio_temporal = create_spatio_temporal_engine(config)
                logger.info("âœ… Spatio-temporal engine initialized - Real-time opportunity discovery ready!")
            except Exception as e:
                logger.warning(f"Spatio-temporal engine not available: {e}")
                self.spatio_temporal = None
            
            # Initialize content generation engine
            logger.info("ðŸŽ¨ Initializing Content Generation Engine...")
            self.content_generator = await create_content_generator(config.DEVICE)
            
            # Initialize Kafka streaming engine
            kafka_url = getattr(config, 'KAFKA_URL', 'kafka://localhost:9092')
            if kafka_url != "kafka://localhost:9092":  # Only if Kafka is configured
                try:
                    logger.info("ðŸŒŠ Initializing Kafka Streaming Engine...")
                    self.kafka_streamer = await create_kafka_streamer(kafka_url, self.redis_client, self.db)
                except Exception as e:
                    logger.warning(f"Kafka streaming disabled: {e}")
                    self.kafka_streamer = None
            else:
                logger.info("ðŸŒŠ Kafka streaming disabled (using default URL)")
                self.kafka_streamer = None
            
            # Initialize social features engine
            logger.info("ðŸ‘¥ Initializing Social Features Engine...")
            self.social_engine = create_social_features_engine(self)
            
            # Initialize affiliate system
            logger.info("ðŸ’° Initializing Affiliate Marketing System...")
            self.affiliate_system = create_affiliate_system(self)
            
            # Core system ready
            logger.info("âœ… Core IBCM AI Engine initialized successfully!")
            
            self.initialized = True
            logger.info("âœ… IBCM AI Engine with ALL COMPLETE Advanced Features ready!")
            
        except Exception as e:
            logger.error(f"âŒ Initialization failed: {e}")
            raise e
    
    async def _connect_databases(self):
        """Connect to MongoDB and Redis"""
        try:
            # MongoDB
            self.mongo_client = pymongo.MongoClient(config.MONGO_URI)
            self.db = self.mongo_client.get_database()
            self.mongo_client.admin.command('ping')
            logger.info("âœ… MongoDB connected")
            
            # Redis
            self.redis_client = redis.from_url(config.REDIS_URL)
            self.redis_client.ping()
            logger.info("âœ… Redis connected")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Database connection failed: {e}")
    
    async def _load_llama_model(self):
        """Load LLaMA model"""
        try:
            logger.info(f"ðŸ¦™ Loading LLaMA model: {config.LLAMA_MODEL}")
            
            # Load tokenizer
            self.tokenizer = AutoTokenizer.from_pretrained(config.LLAMA_MODEL)
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            # Load model with device-specific configuration
            if config.DEVICE == "mps":
                # MPS doesn't support BitsAndBytesConfig - use standard loading
                self.model = AutoModelForCausalLM.from_pretrained(
                    config.LLAMA_MODEL,
                    torch_dtype=torch.float16,
                    trust_remote_code=True
                ).to(config.DEVICE)
            elif config.DEVICE == "cuda":
                # Use quantization for CUDA
                quantization_config = BitsAndBytesConfig(
                    load_in_4bit=True,
                    bnb_4bit_compute_dtype=torch.float16,
                    bnb_4bit_quant_type="nf4",
                    bnb_4bit_use_double_quant=True
                )
                
                self.model = AutoModelForCausalLM.from_pretrained(
                    config.LLAMA_MODEL,
                    quantization_config=quantization_config,
                    device_map="auto",
                    torch_dtype=torch.float16,
                    trust_remote_code=True
                )
            else:
                # CPU fallback
                self.model = AutoModelForCausalLM.from_pretrained(
                    config.LLAMA_MODEL,
                    torch_dtype=torch.float32,
                    trust_remote_code=True
                )
            
            logger.info(f"âœ… LLaMA loaded on {config.DEVICE}")
            
        except Exception as e:
            logger.error(f"âŒ LLaMA loading failed: {e}")
            # Try fallback to open model
            try:
                logger.info("ðŸ”„ Trying fallback model...")
                self.model = AutoModelForCausalLM.from_pretrained(
                    "microsoft/DialoGPT-medium",
                    device_map="auto" if config.DEVICE != "cpu" else None,
                    torch_dtype=torch.float16 if config.DEVICE != "cpu" else torch.float32
                )
                logger.info("âœ… Fallback model loaded successfully")
            except Exception as e2:
                logger.warning(f"âŒ Fallback model also failed: {e2}")
                logger.info("ðŸ“± Using intelligent fallback text generation")
    
    async def _load_embedding_model(self):
        """Load sentence transformer"""
        try:
            self.embedding_model = SentenceTransformer(config.EMBEDDING_MODEL)
            self.faiss_index = faiss.IndexFlatIP(384)  # Dimension for all-MiniLM-L6-v2
            logger.info("âœ… Embedding model loaded")
        except Exception as e:
            logger.error(f"âŒ Embedding model failed: {e}")
    
    async def _build_embeddings(self):
        """Build embeddings from database"""
        try:
            if self.db is None or not self.embedding_model:
                logger.warning("Skipping embeddings - no database or embedding model")
                return
            
            # Get entities from database
            entities = list(self.db.events.find().limit(100))
            if not entities:
                logger.warning("No entities found in database")
                return
            
            # Create embeddings
            texts = []
            entity_ids = []
            
            for entity in entities:
                text = f"{entity.get('title', '')} {entity.get('description', '')} {entity.get('category', '')}"
                texts.append(text)
                entity_ids.append(str(entity.get('_id')))
            
            if texts:
                embeddings = self.embedding_model.encode(texts)
                self.faiss_index.add(embeddings.astype(np.float32))
                
                for i, entity_id in enumerate(entity_ids):
                    self.entity_embeddings[entity_id] = {
                        'embedding': embeddings[i],
                        'text': texts[i],
                        'index': i
                    }
                
                logger.info(f"âœ… Built embeddings for {len(texts)} entities")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Embedding build failed: {e}")
    
    async def generate_response(self, prompt: str) -> str:
        """Generate response using IBCM trained model"""
        try:
            # Use IBCM trained model if available
            if self.ibcm_trained_model and self.ibcm_trained_model.loaded:
                return await self.ibcm_trained_model.generate_response(prompt)
            
            # Fallback to base model if IBCM model not ready
            if not self.model or not self.tokenizer:
                return self._fallback_response(prompt)
            
            # Tokenize
            inputs = self.tokenizer(
                prompt,
                return_tensors="pt",
                truncation=True,
                max_length=2048 - config.MAX_LENGTH,
                padding=True
            )
            
            # Move to device
            if config.DEVICE != "cpu":
                inputs = {k: v.to(self.model.device) for k, v in inputs.items()}
            
            # Generate
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=config.MAX_LENGTH,
                    temperature=config.TEMPERATURE,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id
                )
            
            # Decode
            response = self.tokenizer.decode(
                outputs[0][inputs['input_ids'].shape[1]:],
                skip_special_tokens=True
            )
            
            return response.strip()
            
        except Exception as e:
            logger.error(f"Generation error: {e}")
            return self._fallback_response(prompt)
    
    def _fallback_response(self, prompt: str) -> str:
        """Fallback response when LLaMA not available"""
        prompt_lower = prompt.lower()
        
        if 'spa' in prompt_lower or 'wellness' in prompt_lower:
            return "I found excellent spa and wellness options for you! Try our featured wellness centers with massage therapy, aromatherapy, and relaxation services. Book now for a rejuvenating experience."
        elif 'restaurant' in prompt_lower or 'dining' in prompt_lower:
            return "Here are great dining recommendations! I found authentic restaurants with excellent reviews, diverse cuisines, and perfect ambiance for your dining experience."
        elif 'fitness' in prompt_lower or 'gym' in prompt_lower:
            return "Perfect fitness options available! Check out our recommended gyms and fitness centers with professional trainers, modern equipment, and flexible membership plans."
        else:
            return "I'm here to help you find the best services and experiences! Please let me know what specific type of service you're looking for, and I'll provide personalized recommendations."
    
    async def semantic_search(self, query: str, top_k: int = 5) -> List[Dict]:
        """Perform semantic search with demo fallback"""
        try:
            if not self.embedding_model or not self.faiss_index or self.faiss_index.ntotal == 0:
                return self._get_demo_search_results(query, top_k)
            
            # Encode query
            query_embedding = self.embedding_model.encode([query])
            
            # Search
            scores, indices = self.faiss_index.search(
                query_embedding.astype(np.float32),
                min(top_k, self.faiss_index.ntotal)
            )
            
            # Return results
            results = []
            for score, idx in zip(scores[0], indices[0]):
                if idx < len(self.entity_embeddings):
                    # Find entity by index
                    for entity_id, data in self.entity_embeddings.items():
                        if data.get('index') == idx:
                            results.append({
                                'entity_id': entity_id,
                                'score': float(score),
                                'text': data['text'][:200]
                            })
                            break
            
            return results if results else self._get_demo_search_results(query, top_k)
            
        except Exception as e:
            logger.error(f"Search error: {e}")
            return self._get_demo_search_results(query, top_k)
    
    def _get_demo_search_results(self, query: str, top_k: int) -> List[Dict]:
        """Generate relevant demo search results based on query"""
        query_lower = query.lower()
        
        # Food-related queries
        if any(word in query_lower for word in ['food', 'eat', 'restaurant', 'meal', 'hungry', 'cheap', 'dinner', 'lunch']):
            return [
                {'entity_id': 'demo_1', 'score': 0.95, 'text': 'Pizza Palace - Delicious pizzas starting from â‚¹299, 0.5km away, open until 11 PM'},
                {'entity_id': 'demo_2', 'score': 0.88, 'text': 'Street Food Corner - Best local food, budget-friendly options â‚¹50-150, highly rated'},
                {'entity_id': 'demo_3', 'score': 0.82, 'text': 'Maharaja Restaurant - Traditional Indian cuisine, â‚¹200-400 per person, family-friendly'}
            ][:top_k]
        
        # Entertainment queries
        elif any(word in query_lower for word in ['movie', 'entertainment', 'fun', 'activity', 'do']):
            return [
                {'entity_id': 'demo_4', 'score': 0.92, 'text': 'PVR Cinemas - Latest movies, tickets from â‚¹150, multiple shows daily'},
                {'entity_id': 'demo_5', 'score': 0.85, 'text': 'Fun City Arcade - Gaming and activities, â‚¹300 entry, great for families'},
                {'entity_id': 'demo_6', 'score': 0.78, 'text': 'Comedy Club - Live shows tonight at 8 PM, â‚¹500 tickets, book now'}
            ][:top_k]
        
        # Shopping queries
        elif any(word in query_lower for word in ['shop', 'buy', 'mall', 'store', 'shopping']):
            return [
                {'entity_id': 'demo_7', 'score': 0.90, 'text': 'Phoenix Mall - Premium shopping, 200+ stores, open until 10 PM'},
                {'entity_id': 'demo_8', 'score': 0.83, 'text': 'Local Market - Affordable clothing and accessories, great bargains'},
                {'entity_id': 'demo_9', 'score': 0.77, 'text': 'Electronics Zone - Gadgets and tech products, best prices guaranteed'}
            ][:top_k]
        
        # Services queries
        elif any(word in query_lower for word in ['service', 'help', 'repair', 'fix', 'doctor', 'hospital']):
            return [
                {'entity_id': 'demo_10', 'score': 0.87, 'text': 'Quick Fix Services - Home repairs and maintenance, 24/7 available'},
                {'entity_id': 'demo_11', 'score': 0.84, 'text': 'Apollo Hospital - 24/7 healthcare services, emergency care available'},
                {'entity_id': 'demo_12', 'score': 0.79, 'text': 'Tech Support Center - Computer and mobile repairs, same-day service'}
            ][:top_k]
        
        # Default generic results
        else:
            return [
                {'entity_id': 'demo_13', 'score': 0.75, 'text': f'Premium services for "{query}" - Multiple verified providers in your area'},
                {'entity_id': 'demo_14', 'score': 0.70, 'text': f'Local businesses matching "{query}" - Check nearby locations and reviews'},
                {'entity_id': 'demo_15', 'score': 0.65, 'text': f'Quality options for "{query}" - Best rated services with competitive pricing'}
            ][:top_k]
    
    async def process_query(self, query: str, user_id: str = None, context: Dict = None) -> Dict:
        """Process user query with AI - with proper input validation and text preprocessing"""
        start_time = time.time()
        
        try:
            # Step 1: Validate and clean the query (security)
            validation_result = validate_user_input(query, 'query')
            
            if not validation_result.is_valid:
                logger.warning(f"Invalid query from user {user_id}: {validation_result.blocked_content}")
                return {
                    'success': False,
                    'error': 'Invalid query content',
                    'warnings': validation_result.warnings,
                    'timestamp': datetime.now().isoformat()
                }
            
            clean_query = validation_result.cleaned_input
            
            # Step 2: Text preprocessing and formatting (linguistic improvement)
            preprocessing_result = preprocess_user_text(clean_query, 'query')
            formatted_query = preprocessing_result.formatted_text
            
            logger.info(f"Query preprocessing: '{clean_query}' -> '{formatted_query}' (confidence: {preprocessing_result.confidence_score:.2f})")
            
            # Step 3: Validate context if provided
            clean_context = {}
            if context:
                clean_context = validate_json_data(context)
            
            # Step 4: Semantic search for relevant content (using formatted query)
            search_results = await self.semantic_search(formatted_query, top_k=3)
            
            # Step 4: Build safe context for LLaMA
            search_context = ""
            if search_results:
                search_context = "Relevant options:\n"
                for i, result in enumerate(search_results, 1):
                    # Ensure search result text is also validated
                    safe_text = validate_user_input(result.get('text', ''), 'description')
                    if safe_text.is_valid:
                        search_context += f"{i}. {safe_text.cleaned_input[:200]}\n"
            
            # Step 5: Create safe LLaMA prompt using validation helper
            system_instruction = "You are a helpful assistant for the IBCM platform. Provide helpful, specific responses with relevant recommendations. Be conversational and include actionable advice."
            
            context_str = ""
            if search_context:
                context_str += search_context + "\n"
            if clean_context:
                context_str += f"User Context: {json.dumps(clean_context)}"
            
            safe_prompt = create_safe_llm_prompt(
                user_query=formatted_query,
                context=context_str,
                system_instruction=system_instruction
            )
            
            # Step 6: Generate AI response
            ai_response = await self.generate_response(safe_prompt)
            
            processing_time = time.time() - start_time
            
            return {
                'success': True,
                'original_query': query,
                'cleaned_query': clean_query,
                'formatted_query': formatted_query,
                'response': ai_response,
                'search_results_count': len(search_results),
                'processing_time': round(processing_time, 3),
                'model_used': 'llama' if self.model else 'fallback',
                'validation_warnings': validation_result.warnings,
                'preprocessing_improvements': preprocessing_result.improvements,
                'confidence_score': preprocessing_result.confidence_score,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Query processing error: {e}")
            return {
                'success': False,
                'error': str(e),
                'original_query': query,
                'timestamp': datetime.now().isoformat()
            }
    
    async def get_status(self) -> Dict:
        """Get engine status"""
        return {
            'status': 'operational' if self.initialized else 'initializing',
            'llama_loaded': self.model is not None,
            'embeddings_loaded': self.embedding_model is not None,
            'database_connected': self.db is not None,
            'redis_connected': self.redis_client is not None,
            'embeddings_count': len(self.entity_embeddings),
            'device': config.DEVICE,
            'model': config.LLAMA_MODEL
        }

# Global AI engine
ai_engine = IBCMAIEngine()

from contextlib import asynccontextmanager

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    await ai_engine.initialize()
    yield
    # Shutdown (if needed)
    pass

# FastAPI app
app = FastAPI(
    title="IBCM AI Service - Complete Production API",
    description="""
    ## ðŸš€ Complete IBCM AI Platform
    
    Advanced AI-powered platform for events, recommendations, content generation, and business intelligence.
    
    ### ðŸ§  Core Features:
    - **LLaMA-based AI Processing** - Fine-tuned language model
    - **Vector Search** - FAISS-powered semantic search  
    - **Real-time Agent System** - Planner, Search, Delivery, Analytics agents
    - **Multi-modal Content Generation** - Text, image, video, audio
    
    ### ðŸŽ¯ Specialized Endpoints:
    - **Event Recommendations** - Location-based, personalized
    - **Product Recommendations** - AI-driven suggestions
    - **Business Intelligence** - Analytics and optimization
    - **Social Features** - Feed generation and interaction
    - **Affiliate Marketing** - Link tracking and analytics
    - **Content Creation** - AI-generated marketing content
    
    ### ðŸ”’ Authentication:
    All endpoints require `X-API-Key` header with valid API key.
    
    ### ðŸ“Š Real-time Features:
    - Live streaming integration
    - Spatial search capabilities  
    - Advanced analytics
    - Agent orchestration
    """,
    version="1.0.0-production",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# API Key validation
api_key_header = APIKeyHeader(name="X-API-Key", auto_error=False)

def validate_api_key(api_key: str = Depends(api_key_header)):
    if not api_key or api_key != config.API_KEY:
        raise HTTPException(status_code=401, detail="Invalid API key")
    return api_key

from contextlib import asynccontextmanager

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    await ai_engine.initialize()
    yield
    # Shutdown (if needed)
    pass

@app.get("/")
async def root():
    return {
        "service": "IBCM AI Service - Complete Production API",
        "version": "1.0.0-production",
        "status": "operational" if ai_engine.initialized else "initializing",
        "features": [
            "llama_ai",
            "vector_search", 
            "semantic_matching",
            "advanced_agent_system",
            "spatio_temporal_ai",
            "business_intelligence",
            "social_features",
            "affiliate_marketing",
            "content_generation",
            "personalization",
            "real_time_analytics"
        ],
        "endpoints": {
            # Core AI endpoints
            "basic_query": "/ai/query",
            "agent_query": "/ai/agent-query", 
            "agent_status": "/ai/agents/status",
            "spatial_search": "/ai/spatial-search",
            "analytics": "/ai/analytics",
            "content_generation": "/ai/generate-content",
            "model_info": "/ai/model-info",
            "streaming_status": "/ai/streaming/status",
            "publish_event": "/ai/streaming/publish",
            "status": "/ai/status",
            "health": "/health",
            "docs": "/docs",
            
            # Backend Integration endpoints
            "events_recommend": "/ai/events/recommend",
            "products_recommend": "/ai/products/recommend", 
            "search_enhance": "/ai/search/enhance",
            "chat_respond": "/ai/chat/respond",
            "business_optimize": "/ai/business/optimize",
            
            # Social Features endpoints
            "social_feed": "/ai/social/feed",
            "social_post": "/ai/social/post",
            
            # Affiliate System endpoints
            "affiliate_register": "/ai/affiliate/register",
            "affiliate_link": "/ai/affiliate/link",
            "affiliate_track": "/ai/affiliate/track",
            "affiliate_analytics": "/ai/affiliate/analytics"
        }
    }

@app.post("/ai/query-debug")
async def query_debug(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Debug query endpoint"""
    return {
        "success": True,
        "debug": "Query endpoint is working",
        "request_data": request,
        "api_key_valid": bool(api_key),
        "timestamp": datetime.now().isoformat()
    }

@app.post("/ai/query")
async def query(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Process AI query with real-time context and input validation"""
    
    # Step 1: Validate all incoming request data
    clean_request = validate_json_data(request)
    
    query_text = clean_request.get("query", "")
    user_id = clean_request.get("user_id", "anonymous")
    context = clean_request.get("context", {})
    
    if not query_text:
        raise HTTPException(status_code=400, detail="Query is required")
    
    # Step 2: Security validation for the query text
    validation_result = validate_user_input(query_text, 'query')
    
    if not validation_result.is_valid:
        logger.warning(f"Invalid query attempt: {validation_result.blocked_content}")
        raise HTTPException(
            status_code=400, 
            detail=f"Invalid query content. {'; '.join(validation_result.warnings)}"
        )
    
    clean_query = validation_result.cleaned_input
    
    # Step 3: Text preprocessing and linguistic improvement
    preprocessing_result = preprocess_user_text(clean_query, 'query')
    formatted_query = preprocessing_result.formatted_text
    
    logger.info(f"User query preprocessing: '{clean_query}' -> '{formatted_query}'")
    
    # Step 3: Check for time-sensitive queries first  
    query_lower = clean_query.lower()
    if any(word in query_lower for word in ['time', 'now', 'current', 'today', 'weather', 'trending']):
        current_time = datetime.now()
        realtime_info = {
            "current_time": current_time.strftime('%I:%M %p'),
            "day_of_week": current_time.strftime('%A'),
            "date": current_time.strftime('%B %d, %Y'),
            "season": _get_current_season()
        }
        
        if 'time' in query_lower or 'now' in query_lower:
            response = f"It's currently {realtime_info['current_time']} on {realtime_info['day_of_week']}, {realtime_info['date']}. Perfect timing to explore events and activities!"
        elif 'weather' in query_lower:
            response = f"Today's weather in {realtime_info['season']} is great for outdoor events! I recommend checking local festivals, outdoor dining, or walking tours."
        elif 'trending' in query_lower or 'current' in query_lower:
            response = f"Currently trending: local events, seasonal activities, and {realtime_info['season']} experiences. I can help you find related events in your area!"
        else:
            response = f"This {realtime_info['day_of_week']} is perfect for exploring events! I can help you find activities based on your interests and location."
        
        return {
            "success": True,
            "original_query": query_text,
            "cleaned_query": clean_query,
            "formatted_query": formatted_query,
            "response": response,
            "real_time_context": realtime_info,
            "validation_warnings": validation_result.warnings,
            "preprocessing_improvements": preprocessing_result.improvements,
            "confidence_score": preprocessing_result.confidence_score,
            "timestamp": datetime.now().isoformat()
        }
    
    # Step 4: For other queries, use the improved AI engine with validation
    try:
        result = await ai_engine.process_query(formatted_query, user_id, context)
        # Add preprocessing info to AI engine result
        if isinstance(result, dict):
            result['original_query'] = query_text
            result['preprocessing_improvements'] = preprocessing_result.improvements
            result['confidence_score'] = preprocessing_result.confidence_score
        return result
    except Exception as e:
        logger.error(f"AI query processing error: {e}")
        return {
            "success": True,
            "original_query": query_text,
            "cleaned_query": clean_query,
            "formatted_query": formatted_query,
            "response": f"I understand you're asking about '{formatted_query}'. I'm here to help you find the best services and opportunities. Could you provide more specific details about what you're looking for?",
            "timestamp": datetime.now().isoformat(),
            "mode": "safe_fallback",
            "validation_warnings": validation_result.warnings,
            "preprocessing_improvements": preprocessing_result.improvements,
            "confidence_score": preprocessing_result.confidence_score
        }

@app.post("/ai/agent-query")
async def agent_query(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Process AI query with advanced agent system and input validation"""
    
    # Step 1: Validate all incoming request data
    clean_request = validate_json_data(request)
    
    query_text = clean_request.get("query", "")
    user_id = clean_request.get("user_id", "anonymous")
    context = clean_request.get("context", {})
    
    if not query_text:
        raise HTTPException(status_code=400, detail="Query is required")
    
    # Step 2: Validate the query text
    validation_result = validate_user_input(query_text, 'query')
    
    if not validation_result.is_valid:
        logger.warning(f"Invalid agent query attempt from {user_id}: {validation_result.blocked_content}")
        raise HTTPException(
            status_code=400, 
            detail=f"Invalid query content. {'; '.join(validation_result.warnings)}"
        )
    
    clean_query = validation_result.cleaned_input
    
    if not ai_engine.agent_orchestrator:
        raise HTTPException(status_code=503, detail="Agent system not available")
    
    # Step 3: Process with cleaned inputs
    try:
        result = await ai_engine.agent_orchestrator.process_request(clean_query, user_id, context)
        
        # Add validation info to result
        if isinstance(result, dict):
            result['original_query'] = query_text
            result['processed_query'] = clean_query
            result['validation_warnings'] = validation_result.warnings
        
        return result
    except Exception as e:
        logger.error(f"Agent query processing error: {e}")
        raise HTTPException(status_code=500, detail="Agent processing failed")

@app.get("/ai/agents/status")
async def agent_status(api_key: str = Depends(validate_api_key)):
    """Get agent system status"""
    if not ai_engine.agent_orchestrator:
        return {"agent_system": "not_initialized"}
    
    return await ai_engine.agent_orchestrator.get_status()

@app.post("/ai/spatial-search")
async def spatial_search(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Spatial search with location awareness"""
    query_text = request.get("query", "")
    location = request.get("location", {})
    radius_km = request.get("radius_km", 25)
    
    if not query_text:
        raise HTTPException(status_code=400, detail="Query is required")
    
    if not location.get("lat") or not location.get("lon"):
        raise HTTPException(status_code=400, detail="Location (lat, lon) is required")
    
    context = {
        "location": location,
        "spatial_filter": {"max_distance": radius_km}
    }
    
    if ai_engine.agent_orchestrator:
        return await ai_engine.agent_orchestrator.process_request(query_text, "spatial_user", context)
    else:
        return await ai_engine.process_query(query_text, "spatial_user", context)

@app.post("/ai/analytics")
async def analytics_insights(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Get business analytics and insights"""
    query_text = request.get("query", "")
    category = request.get("category", "")
    
    if not query_text:
        raise HTTPException(status_code=400, detail="Query is required")
    
    # Process query and get analytics
    if ai_engine.agent_orchestrator:
        result = await ai_engine.agent_orchestrator.process_request(query_text, "analytics_user", {})
        
        # Extract analytics from result
        analytics = result.get("agent_workflow", {}).get("analytics", {})
        
        return {
            "query": query_text,
            "analytics": analytics,
            "market_insights": analytics.get("market_insights", []),
            "demand_analysis": analytics.get("demand_analysis", {}),
            "price_trends": analytics.get("price_trends", {}),
            "predictions": analytics.get("predictions", {})
        }
    else:
        return {"error": "Analytics requires agent system"}

@app.get("/ai/status")
async def status(api_key: str = Depends(validate_api_key)):
    """Get AI status"""
    base_status = await ai_engine.get_status()
    
    # Add agent system status
    if ai_engine.agent_orchestrator:
        agent_status = await ai_engine.agent_orchestrator.get_status()
        base_status["agent_system"] = agent_status
    
    return base_status

@app.get("/ai/model-info")
async def get_model_info(api_key: str = Depends(validate_api_key)):
    """Get information about the IBCM trained model"""
    try:
        if ai_engine.ibcm_trained_model:
            model_status = ai_engine.ibcm_trained_model.get_model_status()
            return {
                "success": True,
                "model_status": model_status,
                "message": "IBCM Production Model Status",
                "timestamp": datetime.now().isoformat()
            }
        else:
            return {
                "success": False,
                "error": "IBCM model not loaded",
                "timestamp": datetime.now().isoformat()
            }
        
    except Exception as e:
        logger.error(f"Model info error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/generate-content")
async def generate_content(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Generate multi-modal content (text, images, videos, audio)"""
    if not ai_engine.content_generator:
        raise HTTPException(status_code=503, detail="Content generator not available")
    
    try:
        # Support both old format (event_data) and new format (type + prompt)
        content_type = request.get("type", "text")
        prompt = request.get("prompt", "")
        event_data = request.get("event_data", {})
        
        # If prompt is provided, use the flexible content generation
        if prompt:
            # Create event_data from prompt for compatibility
            event_data = {
                "title": prompt,
                "description": prompt,
                "type": content_type,
                "prompt": prompt
            }
        elif not event_data:
            raise HTTPException(status_code=400, detail="Either 'prompt' or 'event_data' is required")
        
        # Generate comprehensive content package
        content_package = await ai_engine.content_generator.generate_event_content(event_data)
        
        return {
            "success": True,
            "type": content_type,
            "prompt": prompt,
            "content_package": content_package,
            "generated": {
                "text": content_package.get("description", prompt),
                "image_prompt": content_package.get("image_prompt", f"Visual representation of {prompt}"),
                "keywords": content_package.get("keywords", ["ai-generated", "content"]),
                "style": "professional"
            },
            "generation_timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Content generation error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/ai/streaming/status")
async def streaming_status(api_key: str = Depends(validate_api_key)):
    """Get Kafka streaming system status"""
    if not ai_engine.kafka_streamer:
        return {"streaming": "disabled", "reason": "Kafka not configured"}
    
    try:
        status = await ai_engine.kafka_streamer.get_streaming_status()
        return {
            "streaming_enabled": True,
            "kafka_status": status,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Streaming status error: {e}")
        return {"streaming": "error", "error": str(e)}

@app.post("/ai/streaming/publish")
async def publish_streaming_event(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Publish event to Kafka streaming system"""
    if not ai_engine.kafka_streamer:
        raise HTTPException(status_code=503, detail="Streaming not available")
    
    try:
        topic = request.get("topic", "user_activity")
        message = request.get("message", {})
        key = request.get("key")
        
        success = await ai_engine.kafka_streamer.publish_message(topic, message, key)
        
        return {
            "success": success,
            "topic": topic,
            "published_at": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Streaming publish error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "service": "ibcm-ai",
        "timestamp": datetime.now().isoformat()
    }

@app.post("/debug/semantic-search")
async def debug_semantic_search(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Debug endpoint to test semantic search directly"""
    query = request.get("query", "food")
    
    # Test our semantic search directly
    search_results = await ai_engine.semantic_search(query, top_k=5)
    
    return {
        "success": True,
        "query": query,
        "search_results": search_results,
        "results_count": len(search_results),
        "demo_data_active": not (ai_engine.embedding_model and ai_engine.faiss_index and ai_engine.faiss_index.ntotal > 0),
        "timestamp": datetime.now().isoformat()
    }

# Enhanced test endpoints
# ==========================================
# BACKEND INTEGRATION ENDPOINTS
# AI endpoints for backend to call
# ==========================================

@app.post("/ai/events/recommend")
async def recommend_events(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """AI-powered event recommendations for backend"""
    try:
        user_id = request.get("user_id")
        location = request.get("location", {})
        preferences = request.get("preferences", {})
        filters = request.get("filters", {})
        
        # Use agent system for intelligent recommendations
        if ai_engine.agent_orchestrator:
            context = {
                "location": location,
                "preferences": preferences,
                "filters": filters,
                "type": "event_recommendation"
            }
            
            query = f"Recommend events for user in {location.get('city', 'their area')} based on preferences: {preferences}"
            result = await ai_engine.agent_orchestrator.process_request(query, user_id, context)
            
            return {
                "success": True,
                "user_id": user_id,
                "recommendations": result.get("items", []),
                "ai_insights": result.get("ai_insights", {}),
                "timestamp": datetime.now().isoformat()
            }
        else:
            return {
                "success": False,
                "error": "Agent system not available",
                "timestamp": datetime.now().isoformat()
            }
            
    except Exception as e:
        logger.error(f"Event recommendation error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/products/recommend")
async def recommend_products(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """AI-powered product recommendations for backend"""
    try:
        user_id = request.get("user_id")
        category = request.get("category")
        user_history = request.get("user_history", [])
        budget = request.get("budget", {})
        
        context = {
            "category": category,
            "user_history": user_history,
            "budget": budget,
            "type": "product_recommendation"
        }
        
        query = f"Recommend products in {category} category within budget {budget}"
        result = await ai_engine.agent_orchestrator.process_request(query, user_id, context)
        
        return {
            "success": True,
            "user_id": user_id,
            "category": category,
            "recommendations": result.get("items", []),
            "ai_reasoning": result.get("response", ""),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Product recommendation error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/search/enhance")
async def enhance_search(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """AI-enhanced search for backend"""
    try:
        query = request.get("query", "")
        user_id = request.get("user_id")
        search_type = request.get("search_type", "general")
        filters = request.get("filters", {})
        
        if not query:
            raise HTTPException(status_code=400, detail="Query is required")
        
        context = {
            "search_type": search_type,
            "filters": filters,
            "original_query": query
        }
        
        enhanced_result = await ai_engine.agent_orchestrator.process_request(query, user_id, context)
        
        return {
            "success": True,
            "original_query": query,
            "enhanced_query": enhanced_result.get("enhanced_query", query),
            "search_suggestions": enhanced_result.get("suggestions", []),
            "semantic_results": enhanced_result.get("items", []),
            "ai_insights": enhanced_result.get("ai_insights", {}),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Search enhancement error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/chat/respond")
async def ai_chat_response(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """AI chat response for backend"""
    try:
        message = request.get("message", "")
        user_id = request.get("user_id")
        chat_history = request.get("chat_history", [])
        context = request.get("context", {})
        
        if not message:
            raise HTTPException(status_code=400, detail="Message is required")
        
        # Add chat history to context
        if chat_history:
            context["chat_history"] = chat_history[-5:]  # Last 5 messages for context
        
        response = await ai_engine.agent_orchestrator.process_request(message, user_id, context)
        
        return {
            "success": True,
            "user_id": user_id,
            "user_message": message,
            "ai_response": response.get("response", ""),
            "intent": response.get("agent_workflow", {}).get("planner", {}).get("intent", "general"),
            "suggestions": response.get("recommendations", []),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Chat response error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/business/optimize")
async def business_optimization(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """AI-powered business optimization for backend"""
    try:
        business_id = request.get("business_id")
        optimization_type = request.get("type")  # pricing, inventory, marketing, scheduling
        business_data = request.get("business_data", {})
        target_metrics = request.get("target_metrics", {})
        
        context = {
            "business_id": business_id,
            "optimization_type": optimization_type,
            "business_data": business_data,
            "target_metrics": target_metrics
        }
        
        query = f"Optimize {optimization_type} for business {business_id}"
        result = await ai_engine.agent_orchestrator.process_request(query, "business_ai", context)
        
        return {
            "success": True,
            "business_id": business_id,
            "optimization_type": optimization_type,
            "recommendations": result.get("items", []),
            "ai_insights": result.get("ai_insights", {}),
            "action_items": result.get("recommendations", []),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Business optimization error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==========================================
# SOCIAL FEATURES ENDPOINTS
# ==========================================

@app.get("/ai/social/feed")
async def get_social_feed(
    user_id: str,
    limit: int = 20,
    api_key: str = Depends(validate_api_key)
):
    """Get personalized social feed for user"""
    try:
        if not ai_engine.social_engine:
            raise HTTPException(status_code=503, detail="Social features not available")
        
        feed = await ai_engine.social_engine.generate_personalized_feed(user_id, limit)
        
        return {
            "success": True,
            "user_id": user_id,
            "feed": feed,
            "count": len(feed),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Social feed error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/social/post")
async def create_social_post(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Create new social post with AI enhancement"""
    try:
        if not ai_engine.social_engine:
            raise HTTPException(status_code=503, detail="Social features not available")
        
        user_id = request.get("user_id")
        content = request.get("content", "")
        media = request.get("media", [])
        tags = request.get("tags", [])
        
        if not user_id or not content:
            raise HTTPException(status_code=400, detail="User ID and content are required")
        
        result = await ai_engine.social_engine.create_social_post(user_id, content, media, tags)
        
        return {
            "success": result["success"],
            "post": result.get("post", {}),
            "message": result.get("message", ""),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Social post error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==========================================
# AFFILIATE SYSTEM ENDPOINTS
# ==========================================

@app.post("/ai/affiliate/register")
async def register_affiliate(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Register new affiliate partner"""
    try:
        if not ai_engine.affiliate_system:
            raise HTTPException(status_code=503, detail="Affiliate system not available")
        
        result = await ai_engine.affiliate_system.register_affiliate(request)
        
        return {
            "success": result["success"],
            "affiliate_id": result.get("affiliate_id"),
            "tracking_code": result.get("tracking_code"),
            "message": result.get("message", ""),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Affiliate registration error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/affiliate/link")
async def create_affiliate_link(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Create trackable affiliate link"""
    try:
        if not ai_engine.affiliate_system:
            raise HTTPException(status_code=503, detail="Affiliate system not available")
        
        affiliate_id = request.get("affiliate_id")
        product_data = request.get("product_data", {})
        
        if not affiliate_id:
            raise HTTPException(status_code=400, detail="Affiliate ID is required")
        
        result = await ai_engine.affiliate_system.create_affiliate_link(affiliate_id, product_data)
        
        return {
            "success": result["success"],
            "link_id": result.get("link_id"),
            "tracking_url": result.get("tracking_url"),
            "commission_rate": result.get("commission_rate"),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Affiliate link creation error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/affiliate/track")
async def track_affiliate_activity(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Track affiliate clicks and conversions"""
    try:
        if not ai_engine.affiliate_system:
            raise HTTPException(status_code=503, detail="Affiliate system not available")
        
        action_type = request.get("action_type")  # click, conversion
        tracking_data = request.get("tracking_data", {})
        
        if action_type == "click":
            result = await ai_engine.affiliate_system.track_click(
                tracking_data.get("tracking_code"),
                tracking_data.get("link_id"),
                tracking_data.get("user_data", {})
            )
        elif action_type == "conversion":
            result = await ai_engine.affiliate_system.track_conversion(
                tracking_data.get("click_id"),
                tracking_data.get("transaction_data", {})
            )
        else:
            raise HTTPException(status_code=400, detail="Invalid action type")
        
        return {
            "success": result["success"],
            "data": result,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Affiliate tracking error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/ai/affiliate/analytics")
async def get_affiliate_analytics(
    affiliate_id: str,
    period_days: int = 30,
    api_key: str = Depends(validate_api_key)
):
    """Get affiliate performance analytics"""
    try:
        if not ai_engine.affiliate_system:
            raise HTTPException(status_code=503, detail="Affiliate system not available")
        
        result = await ai_engine.affiliate_system.get_affiliate_analytics(affiliate_id, period_days)
        
        return {
            "success": result["success"],
            "analytics": result.get("analytics", {}),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Affiliate analytics error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==========================================
# TEST ENDPOINTS (for development)
# ==========================================

@app.post("/ai/test/wellness")
async def test_wellness(api_key: str = Depends(validate_api_key)):
    """Test wellness search with agent system"""
    context = {
        "location": {"lat": 40.7128, "lon": -74.0060, "city": "NYC"},
        "preferences": ["wellness", "spa", "massage", "relaxation"]
    }
    
    if ai_engine.agent_orchestrator:
        return await ai_engine.agent_orchestrator.process_request(
            "Find the best spa and wellness centers with massage therapy near me",
            "wellness_test_user",
            context
        )
    else:
        return await ai_engine.process_query(
            "Find spa and wellness centers for relaxation and massage therapy",
            "test_user",
            context
        )

@app.post("/ai/test/dining")
async def test_dining(api_key: str = Depends(validate_api_key)):
    """Test dining search with agent system"""
    context = {
        "location": {"lat": 40.7590, "lon": -73.9850, "city": "NYC"},
        "preferences": ["romantic", "authentic", "italian", "wine"]
    }
    
    if ai_engine.agent_orchestrator:
        return await ai_engine.agent_orchestrator.process_request(
            "Recommend authentic Italian restaurants with romantic atmosphere for a special dinner",
            "dining_test_user",
            context
        )
    else:
        return await ai_engine.process_query(
            "Recommend authentic restaurants for a romantic dinner",
            "test_user",
            context
        )

@app.post("/ai/test/spatial")
async def test_spatial(api_key: str = Depends(validate_api_key)):
    """Test spatial search capabilities"""
    context = {
        "location": {"lat": 40.7620, "lon": -73.9780, "city": "NYC"},
        "preferences": ["fitness", "yoga", "community"]
    }
    
    if ai_engine.agent_orchestrator:
        return await ai_engine.agent_orchestrator.process_request(
            "Find fitness studios and yoga classes within 10km that have a community atmosphere",
            "spatial_test_user", 
            context
        )
    else:
        return {"error": "Spatial search requires agent system"}

@app.post("/ai/test/analytics")
async def test_analytics(api_key: str = Depends(validate_api_key)):
    """Test analytics capabilities"""
    if ai_engine.agent_orchestrator:
        result = await ai_engine.agent_orchestrator.process_request(
            "Analyze the wellness market trends and pricing in New York",
            "analytics_test_user",
            {"category": "wellness"}
        )
        
        return {
            "test_type": "analytics",
            "full_result": result,
            "analytics_focus": result.get("agent_workflow", {}).get("analytics", {})
        }
    else:
        return {"error": "Analytics requires agent system"}

# ==========================================
# UNIVERSAL AI ENDPOINTS - ALL NICHES
# ==========================================

@app.post("/ai/universal/financial-advice")
async def universal_financial_advice(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Universal financial advice - investment, banking, insurance, budgeting"""
    try:
        query = request.get("query", "")
        risk_tolerance = request.get("risk_tolerance", "moderate")
        goals = request.get("goals", [])
        budget = request.get("budget", {})
        
        # Try universal orchestrator first
        if hasattr(ai_engine, 'universal_orchestrator') and ai_engine.universal_orchestrator:
            try:
                analysis = await ai_engine.universal_orchestrator.process_universal_query(
                    query, "financial", {
                        "portfolio": request.get("portfolio", {}),
                        "risk_tolerance": risk_tolerance,
                        "goals": goals,
                        "budget": budget,
                        "current_situation": request.get("current_situation", {})
                    }
                )
                
                return {
                    "success": True,
                    "domain": "financial",
                    "analysis": analysis.__dict__,
                    "personalized_recommendations": analysis.recommendations,
                    "pricing_insights": analysis.pricing_analysis,
                    "market_analysis": analysis.market_insights,
                    "action_plan": analysis.next_steps,
                    "risk_assessment": analysis.risk_assessment,
                    "confidence_score": analysis.confidence
                }
            except Exception as e:
                logger.warning(f"Universal orchestrator failed, using fallback: {e}")
        
        # Fallback financial analysis
        recommendations = []
        pricing_analysis = {}
        
        if "stock" in query.lower() or "investment" in query.lower():
            recommendations = [
                {
                    "investment": "Diversified Stock Portfolio",
                    "allocation": "60-70% stocks, 30-40% bonds",
                    "expected_return": "7-10% annually",
                    "risk_level": risk_tolerance,
                    "rationale": f"Based on {risk_tolerance} risk tolerance, recommend balanced approach with growth potential"
                },
                {
                    "investment": "Index Funds (S&P 500)",
                    "allocation": "Core holding 40-50%",
                    "current_price": "$450-500 per share",
                    "expected_return": "8-12% annually",
                    "rationale": "Low-cost diversification with historical strong performance"
                }
            ]
            pricing_analysis = {
                "market_timing": "Current market shows mixed signals - dollar-cost averaging recommended",
                "cost_analysis": "Index funds: 0.03-0.1% expense ratio, Individual stocks: $0 commission most brokers",
                "total_investment_suggestion": f"Start with ${budget.get('amount', 10000)} and invest monthly"
            }
        
        elif "real estate" in query.lower():
            recommendations = [
                {
                    "investment": "Real Estate Investment Trusts (REITs)",
                    "allocation": "5-15% of portfolio",
                    "expected_return": "6-9% annually",
                    "rationale": "Real estate exposure without direct property management"
                },
                {
                    "investment": "Primary Residence Purchase",
                    "down_payment": "10-20% of home value",
                    "expected_appreciation": "3-5% annually",
                    "rationale": "Build equity while having place to live"
                }
            ]
            pricing_analysis = {
                "market_analysis": "Real estate prices vary by location - research local markets",
                "financing": "Mortgage rates 6.5-7.5%, consider fixed vs adjustable",
                "total_cost": "Factor in maintenance, taxes, insurance beyond mortgage"
            }
        
        return {
            "success": True,
            "domain": "financial",
            "query": query,
            "personalized_recommendations": recommendations,
            "pricing_insights": pricing_analysis,
            "market_analysis": {
                "current_conditions": "Mixed market signals - caution advised",
                "opportunities": ["Technology sector recovery", "International diversification"],
                "risks": ["Interest rate volatility", "Inflation persistence"]
            },
            "action_plan": [
                "Research recommended investment options",
                "Consider risk tolerance and time horizon",
                "Start with small amounts and scale up",
                "Consult financial advisor for large investments"
            ],
            "risk_assessment": {
                "risk_level": risk_tolerance,
                "suitability": f"Recommendations matched to {risk_tolerance} risk profile",
                "diversification": "Spread investments across asset classes"
            },
            "confidence_score": 0.85
        }
        
    except Exception as e:
        logger.error(f"Financial advice error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/universal/healthcare-advisor")
async def universal_healthcare_advisor(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Universal healthcare advice - symptoms, providers, costs, wellness"""
    try:
        query = request.get("query", "")
        symptoms = request.get("symptoms", [])
        location = request.get("location", {})
        insurance = request.get("insurance", {})
        
        # Try universal orchestrator first
        if hasattr(ai_engine, 'universal_orchestrator') and ai_engine.universal_orchestrator:
            try:
                analysis = await ai_engine.universal_orchestrator.process_universal_query(
                    query, "healthcare", {
                        "symptoms": symptoms,
                        "medical_history": request.get("medical_history", {}),
                        "location": location,
                        "insurance": insurance,
                        "preferences": request.get("preferences", {})
                    }
                )
                
                return {
                    "success": True,
                    "domain": "healthcare",
                    "analysis": analysis.__dict__,
                    "provider_recommendations": analysis.recommendations,
                    "cost_analysis": analysis.pricing_analysis,
                    "urgency_assessment": analysis.risk_assessment,
                    "next_steps": analysis.next_steps,
                    "market_insights": analysis.market_insights,
                    "confidence_score": analysis.confidence,
                    "disclaimer": "This is not medical advice. Consult healthcare professionals for medical decisions."
                }
            except Exception as e:
                logger.warning(f"Universal orchestrator failed, using fallback: {e}")
        
        # Fallback healthcare analysis
        provider_recommendations = []
        cost_analysis = {}
        urgency_level = "non-urgent"
        
        # Analyze symptoms for urgency
        emergency_symptoms = ["chest pain", "difficulty breathing", "severe bleeding", "loss of consciousness"]
        urgent_symptoms = ["high fever", "severe pain", "persistent vomiting", "injury"]
        
        if any(symptom.lower() in query.lower() for symptom in emergency_symptoms):
            urgency_level = "emergency"
            provider_recommendations = [
                {
                    "provider_type": "Emergency Room",
                    "urgency": "Immediate",
                    "cost_range": "$1,500-5,000",
                    "rationale": "Emergency symptoms require immediate medical attention",
                    "action": "Call 911 or go to nearest ER immediately"
                }
            ]
        elif any(symptom.lower() in query.lower() for symptom in urgent_symptoms):
            urgency_level = "urgent"
            provider_recommendations = [
                {
                    "provider_type": "Urgent Care",
                    "wait_time": "1-3 hours",
                    "cost_range": "$150-400",
                    "rationale": "Urgent symptoms need same-day care",
                    "action": "Visit urgent care or call healthcare provider"
                },
                {
                    "provider_type": "Telehealth",
                    "wait_time": "Same day",
                    "cost_range": "$40-100",
                    "rationale": "Quick initial assessment and guidance",
                    "action": "Schedule telehealth consultation for triage"
                }
            ]
        else:
            # Non-urgent care
            if "headache" in query.lower() or "fatigue" in query.lower():
                provider_recommendations = [
                    {
                        "provider_type": "Primary Care Physician",
                        "wait_time": "1-2 weeks",
                        "cost_range": "$200-350",
                        "rationale": "Persistent symptoms need professional evaluation",
                        "action": "Schedule appointment with your primary care doctor"
                    },
                    {
                        "provider_type": "Telehealth Consultation",
                        "wait_time": "Same day",
                        "cost_range": "$40-80",
                        "rationale": "Initial assessment can be done remotely",
                        "action": "Try telehealth first for convenience and cost savings"
                    }
                ]
        
        # Cost analysis
        cost_analysis = {
            "insurance_considerations": {
                "with_insurance": "Copay typically $20-50 for primary care, $40-80 for specialists",
                "without_insurance": "Full cost applies - consider payment plans",
                "preventive_care": "Usually covered 100% by insurance"
            },
            "cost_saving_tips": [
                "Use in-network providers to minimize costs",
                "Consider telehealth for initial consultations",
                "Ask about generic medications if prescribed",
                "Use urgent care instead of ER for non-emergency issues"
            ],
            "estimated_total": "Total cost depends on diagnosis and treatment plan"
        }
        
        return {
            "success": True,
            "domain": "healthcare",
            "query": query,
            "symptoms_analyzed": symptoms,
            "provider_recommendations": provider_recommendations,
            "cost_analysis": cost_analysis,
            "urgency_assessment": {
                "level": urgency_level,
                "timeframe": "Seek care within 24 hours" if urgency_level == "urgent" else "Schedule routine appointment",
                "warning_signs": "Seek immediate care if symptoms worsen or new symptoms develop"
            },
            "next_steps": [
                "Monitor symptoms and track any changes",
                "Prepare list of current medications",
                "Document symptom timeline and severity",
                "Contact healthcare provider as recommended"
            ],
            "market_insights": {
                "telehealth_growth": "Telehealth usage increased 300% since 2020",
                "cost_trends": "Healthcare costs rising 3-5% annually",
                "access_improvements": "More providers offering same-day appointments"
            },
            "confidence_score": 0.75,
            "disclaimer": "This is not medical advice. Consult healthcare professionals for medical decisions."
        }
        
    except Exception as e:
        logger.error(f"Healthcare advisor error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/universal/education-planner")
async def universal_education_planner(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Universal education planning - skills, courses, career development"""
    try:
        analysis = await ai_engine.universal_orchestrator.process_universal_query(
            request.get("query", ""),
            "education",
            {
                "current_skills": request.get("current_skills", []),
                "target_skills": request.get("target_skills", []),
                "learning_style": request.get("learning_style", "mixed"),
                "time_available": request.get("time_available", 5),
                "budget": request.get("budget", {}),
                "career_goals": request.get("career_goals", [])
            }
        )
        
        return {
            "success": True,
            "domain": "education",
            "analysis": analysis.__dict__,
            "learning_path": analysis.recommendations,
            "cost_analysis": analysis.pricing_analysis,
            "timeline": analysis.next_steps,
            "skill_gap_analysis": analysis.risk_assessment,
            "market_insights": analysis.market_insights,
            "confidence_score": analysis.confidence
        }
        
    except Exception as e:
        logger.error(f"Education planner error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/universal/business-optimizer")
async def universal_business_optimizer(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Universal business optimization - strategy, growth, costs, pricing"""
    try:
        analysis = await ai_engine.universal_orchestrator.process_universal_query(
            request.get("query", ""),
            "business",
            {
                "business_metrics": request.get("business_metrics", {}),
                "goals": request.get("goals", []),
                "industry": request.get("industry", ""),
                "competitors": request.get("competitors", []),
                "budget": request.get("budget", {})
            }
        )
        
        return {
            "success": True,
            "domain": "business",
            "analysis": analysis.__dict__,
            "optimization_strategies": analysis.recommendations,
            "cost_analysis": analysis.pricing_analysis,
            "growth_plan": analysis.next_steps,
            "risk_assessment": analysis.risk_assessment,
            "market_insights": analysis.market_insights,
            "confidence_score": analysis.confidence
        }
        
    except Exception as e:
        logger.error(f"Business optimizer error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/universal/lifestyle-advisor")
async def universal_lifestyle_advisor(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Universal lifestyle advice - home, family, automotive, sustainability"""
    try:
        category = request.get("category", "general")  # home, family, automotive, sustainability
        
        recommendations = []
        pricing_analysis = {}
        
        if category == "home":
            recommendations = [
                {
                    "type": "Home Improvement",
                    "suggestion": "Kitchen renovation for $25-50K adds 60-80% value",
                    "cost_range": "$25,000-50,000",
                    "roi": "60-80% of investment"
                },
                {
                    "type": "Energy Efficiency", 
                    "suggestion": "Solar panels: $15-25K investment, 6-10 year payback",
                    "cost_range": "$15,000-25,000",
                    "roi": "15-20% annual savings on electricity"
                }
            ]
            pricing_analysis = {
                "renovation_costs": "Vary by region, materials, and scope",
                "financing_options": "Home equity loans, personal loans, contractor financing",
                "best_timing": "Off-season work often 10-20% cheaper"
            }
        
        elif category == "automotive":
            recommendations = [
                {
                    "type": "Vehicle Purchase",
                    "suggestion": "EV vs Gas comparison shows EV savings of $1200/year in fuel",
                    "cost_range": "EVs: $25K-60K, Gas: $20K-50K",
                    "roi": "Break-even in 4-6 years"
                },
                {
                    "type": "Maintenance",
                    "suggestion": "Preventive maintenance saves 40% vs reactive repairs",
                    "cost_range": "$500-1500/year preventive vs $2000-5000 reactive",
                    "roi": "40-60% cost savings"
                }
            ]
            pricing_analysis = {
                "total_cost_ownership": "Include purchase, fuel, maintenance, insurance",
                "depreciation": "New cars lose 20% value first year",
                "optimal_timing": "Model year-end for discounts"
            }
        
        return {
            "success": True,
            "domain": "lifestyle",
            "category": category,
            "recommendations": recommendations,
            "pricing_analysis": pricing_analysis,
            "market_insights": {
                "trends": f"Current trends in {category} market",
                "cost_factors": "Location, timing, and quality affect pricing"
            },
            "next_steps": [
                f"Research {category} options in your area",
                "Get multiple quotes for comparison",
                "Consider seasonal timing for better prices"
            ]
        }
        
    except Exception as e:
        logger.error(f"Lifestyle advisor error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/universal/market-intelligence")
async def universal_market_intelligence(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Universal market intelligence across all domains"""
    try:
        domain = request.get("domain", "general")
        query = request.get("query", "")
        
        # Generate market intelligence based on domain
        market_data = {
            "financial": {
                "market_sentiment": "Cautiously optimistic",
                "key_trends": ["AI investment growth", "Interest rate stabilization", "ESG investing"],
                "opportunities": ["Tech sector recovery", "Emerging markets", "Infrastructure spending"],
                "risks": ["Inflation persistence", "Geopolitical tensions", "Market volatility"]
            },
            "healthcare": {
                "market_sentiment": "Growth focused",
                "key_trends": ["Telehealth adoption", "AI diagnostics", "Personalized medicine"],
                "opportunities": ["Digital health", "Aging population", "Preventive care"],
                "risks": ["Regulatory changes", "Data privacy", "Cost pressures"]
            },
            "education": {
                "market_sentiment": "Transformation period",
                "key_trends": ["Online learning", "Skill-based hiring", "AI tutoring"],
                "opportunities": ["Professional certifications", "Micro-learning", "Corporate training"],
                "risks": ["Traditional model disruption", "Technology barriers", "Quality concerns"]
            },
            "business": {
                "market_sentiment": "Efficiency focused",
                "key_trends": ["AI automation", "Remote work", "Sustainability"],
                "opportunities": ["Digital transformation", "E-commerce", "Green technology"],
                "risks": ["Economic uncertainty", "Labor shortages", "Cyber threats"]
            }
        }
        
        domain_data = market_data.get(domain, market_data["financial"])
        
        return {
            "success": True,
            "domain": domain,
            "query": query,
            "market_intelligence": domain_data,
            "price_trends": {
                "direction": "Mixed signals across sectors",
                "volatility": "Moderate to high",
                "key_drivers": ["Economic indicators", "Consumer confidence", "Policy changes"]
            },
            "investment_outlook": {
                "short_term": "Cautious approach recommended",
                "medium_term": "Selective opportunities",
                "long_term": "Structural growth themes intact"
            },
            "recommendations": [
                f"Monitor {domain} sector developments closely",
                "Diversify across multiple opportunities",
                "Consider professional consultation for major decisions"
            ]
        }
        
    except Exception as e:
        logger.error(f"Market intelligence error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/universal/price-optimizer")
async def universal_price_optimizer(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Universal price optimization across all domains"""
    try:
        category = request.get("category", "")
        item = request.get("item", "")
        budget = request.get("budget", {})
        
        optimization_strategies = {
            "general": [
                {
                    "strategy": "Comparison Shopping",
                    "description": "Compare prices across 3+ providers",
                    "potential_savings": "10-30%",
                    "tools": ["Google Shopping", "PriceGrabber", "Shopping.com"]
                },
                {
                    "strategy": "Timing Optimization", 
                    "description": "Purchase during off-peak seasons",
                    "potential_savings": "15-40%",
                    "best_times": "End of model years, holiday sales, clearance events"
                },
                {
                    "strategy": "Bulk/Volume Discounts",
                    "description": "Group purchases for better rates",
                    "potential_savings": "5-25%",
                    "application": "Business supplies, insurance, utilities"
                }
            ]
        }
        
        # Price prediction based on category
        price_insights = {
            "current_market": "Moderate price levels",
            "trend_direction": "Stable with seasonal fluctuations",
            "optimal_timing": "Compare prices weekly, buy during sales",
            "risk_factors": ["Supply chain", "Demand cycles", "Economic conditions"]
        }
        
        return {
            "success": True,
            "category": category,
            "item": item,
            "optimization_strategies": optimization_strategies["general"],
            "price_insights": price_insights,
            "budget_analysis": {
                "recommended_range": "Research market rates + 10-20% buffer",
                "cost_factors": ["Quality", "Location", "Timing", "Volume"],
                "financing_options": "Consider total cost vs monthly payments"
            },
            "next_steps": [
                "Set price alerts for target items",
                "Research historical pricing trends",
                "Compare total cost of ownership",
                "Negotiate for better pricing"
            ]
        }
        
    except Exception as e:
        logger.error(f"Price optimizer error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Enhanced training endpoint for universal data
@app.post("/ai/universal/train")
async def train_universal_model(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Train AI model on universal data from all 50+ niches"""
    try:
        if not ai_engine.universal_trainer:
            return {
                "success": False,
                "error": "Universal trainer not available",
                "message": "Universal web training modules not loaded"
            }
        
        # Scrape universal data
        logger.info("ðŸŒ Starting universal data scraping...")
        universal_data = await ai_engine.universal_trainer.scrape_universal_data(
            max_examples_per_niche=request.get("examples_per_niche", 50)
        )
        
        # Training summary
        training_summary = {
            "total_examples": len(universal_data),
            "domains_covered": list(set([item.get('domain', 'unknown') for item in universal_data])),
            "data_sources": list(set([item.get('source', 'unknown') for item in universal_data])),
            "training_started": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "message": "Universal training data collected successfully",
            "training_summary": training_summary,
            "next_steps": [
                "Data preprocessing and cleaning",
                "Model fine-tuning with domain-specific data",
                "Validation across all niches",
                "Production deployment"
            ]
        }
        
    except Exception as e:
        logger.error(f"Universal training error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==========================================
# REAL-TIME STOCK EXCHANGE ENDPOINTS
# ==========================================

@app.post("/ai/price-exchange/live-offers")
async def get_live_price_offers(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Get live price offers like a stock exchange - real-time pricing for pubs, restaurants, hotels, services"""
    try:
        query = request.get("query", "")
        user_location = request.get("location", {"city": "London", "lat": 51.5074, "lon": -0.1278})
        service_types = request.get("service_types", None)
        
        if not ai_engine.price_exchange:
            # Fallback with static examples
            return {
                "success": True,
                "message": "Price exchange demo mode",
                "live_offers": [
                    {
                        "provider_name": "The Golden Lion Pub",
                        "service_type": "pub",
                        "original_price": 45.0,
                        "current_price": 31.5,
                        "discount_percentage": 30,
                        "deal_type": "happy_hour",
                        "available_until": (datetime.now() + timedelta(hours=2)).isoformat(),
                        "urgency_score": 0.8,
                        "city": "London"
                    },
                    {
                        "provider_name": "Bella Italia Restaurant",
                        "service_type": "restaurant",
                        "original_price": 85.0,
                        "current_price": 55.25,
                        "discount_percentage": 35,
                        "deal_type": "last_minute_dinner",
                        "available_until": (datetime.now() + timedelta(minutes=30)).isoformat(),
                        "urgency_score": 0.95,
                        "city": "Paris"
                    }
                ],
                "total_offers": 2,
                "query_processed": query
            }
        
        # Get real-time offers
        offers = await ai_engine.price_exchange.get_real_time_offers(query, user_location, service_types)
        
        return {
            "success": True,
            "live_offers": [
                {
                    "provider_id": offer.provider_id,
                    "provider_name": offer.provider_name,
                    "service_type": offer.service_type,
                    "original_price": offer.original_price,
                    "current_price": offer.current_price,
                    "discount_percentage": offer.discount_percentage,
                    "deal_type": offer.deal_type,
                    "available_until": offer.available_until.isoformat(),
                    "capacity_remaining": offer.capacity_remaining,
                    "urgency_score": offer.urgency_score,
                    "quality_rating": offer.quality_rating,
                    "city": offer.city,
                    "location": offer.location
                } for offer in offers
            ],
            "total_offers": len(offers),
            "query_processed": query,
            "user_location": user_location,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Live offers error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/price-exchange/flash-deals")
async def get_flash_deals(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Get flash deals and last-minute offers with high urgency"""
    try:
        service_type = request.get("service_type", None)
        city = request.get("city", None)
        
        if not ai_engine.price_exchange:
            return {
                "success": True,
                "message": "Flash deals demo mode", 
                "flash_deals": [
                    {
                        "provider_name": "Steakhouse Prime",
                        "service_type": "restaurant",
                        "original_price": 95.0,
                        "current_price": 47.5,
                        "discount_percentage": 50,
                        "deal_type": "flash_sale",
                        "available_until": (datetime.now() + timedelta(hours=2)).isoformat(),
                        "urgency_score": 0.95,
                        "capacity_remaining": 2
                    }
                ]
            }
        
        deals = await ai_engine.price_exchange.get_flash_deals(service_type, city)
        
        return {
            "success": True,
            "flash_deals": [
                {
                    "provider_id": deal.provider_id,
                    "provider_name": deal.provider_name,
                    "service_type": deal.service_type,
                    "original_price": deal.original_price,
                    "current_price": deal.current_price,
                    "discount_percentage": deal.discount_percentage,
                    "deal_type": deal.deal_type,
                    "available_until": deal.available_until.isoformat(),
                    "capacity_remaining": deal.capacity_remaining,
                    "urgency_score": deal.urgency_score,
                    "city": deal.city,
                    "time_remaining": str(deal.available_until - datetime.now())
                } for deal in deals
            ],
            "total_deals": len(deals),
            "filters_applied": {
                "service_type": service_type,
                "city": city
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Flash deals error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/price-exchange/price-tracker")
async def track_price_changes(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Track price changes for specific providers like stock tracking"""
    try:
        provider_id = request.get("provider_id", "")
        service_type = request.get("service_type", "")
        
        if not provider_id or not service_type:
            raise HTTPException(status_code=400, detail="provider_id and service_type are required")
        
        if not ai_engine.price_exchange:
            return {
                "success": True,
                "message": "Price tracking demo mode",
                "price_tracking": {
                    "provider_id": provider_id,
                    "service_type": service_type,
                    "current_price": 45.0,
                    "average_price_24h": 47.5,
                    "min_price_24h": 31.5,
                    "max_price_24h": 52.0,
                    "price_trend": "down",
                    "volatility": 20.5,
                    "recommendation": "Good time to book - prices below average"
                }
            }
        
        tracking_data = await ai_engine.price_exchange.track_price_changes(provider_id, service_type)
        
        return {
            "success": True,
            "price_tracking": tracking_data,
            "recommendations": {
                "action": "buy" if tracking_data.get("price_trend") == "down" else "wait",
                "reasoning": "Prices are trending down - good opportunity" if tracking_data.get("price_trend") == "down" else "Prices are rising - consider waiting",
                "confidence": 0.8
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Price tracking error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/price-exchange/city-compare")
async def compare_city_prices(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """Compare prices across different cities for same services"""
    try:
        service_type = request.get("service_type", "pubs")
        cities = request.get("cities", ["London", "Paris", "New York"])
        
        city_comparisons = []
        
        for city in cities:
            if ai_engine.price_exchange:
                offers = await ai_engine.price_exchange.get_real_time_offers(
                    f"{service_type} in {city}", 
                    {"city": city}, 
                    [service_type]
                )
                
                if offers:
                    avg_price = sum(offer.current_price for offer in offers) / len(offers)
                    min_price = min(offer.current_price for offer in offers)
                    max_price = max(offer.current_price for offer in offers)
                    best_deal = min(offers, key=lambda x: x.current_price)
                    
                    city_comparisons.append({
                        "city": city,
                        "average_price": round(avg_price, 2),
                        "min_price": min_price,
                        "max_price": max_price,
                        "price_range": f"${min_price} - ${max_price}",
                        "offers_count": len(offers),
                        "best_deal": {
                            "provider": best_deal.provider_name,
                            "price": best_deal.current_price,
                            "discount": best_deal.discount_percentage
                        }
                    })
            else:
                # Demo data for cities
                demo_prices = {
                    "London": {"avg": 42.5, "min": 31.5, "max": 52.0},
                    "Paris": {"avg": 67.5, "min": 55.25, "max": 85.0},
                    "New York": {"avg": 51.5, "min": 38.4, "max": 65.0}
                }
                
                if city in demo_prices:
                    data = demo_prices[city]
                    city_comparisons.append({
                        "city": city,
                        "average_price": data["avg"],
                        "min_price": data["min"],
                        "max_price": data["max"],
                        "price_range": f"${data['min']} - ${data['max']}",
                        "offers_count": 5,
                        "demo_mode": True
                    })
        
        # Sort by average price
        city_comparisons.sort(key=lambda x: x["average_price"])
        
        return {
            "success": True,
            "service_type": service_type,
            "city_comparisons": city_comparisons,
            "cheapest_city": city_comparisons[0]["city"] if city_comparisons else None,
            "most_expensive_city": city_comparisons[-1]["city"] if city_comparisons else None,
            "price_difference": round(city_comparisons[-1]["average_price"] - city_comparisons[0]["average_price"], 2) if len(city_comparisons) > 1 else 0,
            "recommendations": [
                f"Best value: {city_comparisons[0]['city']} with average ${city_comparisons[0]['average_price']}" if city_comparisons else "No data available",
                f"Consider avoiding: {city_comparisons[-1]['city']} - {round((city_comparisons[-1]['average_price'] - city_comparisons[0]['average_price']) / city_comparisons[0]['average_price'] * 100, 1)}% more expensive" if len(city_comparisons) > 1 else ""
            ],
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"City comparison error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==========================================
# SPATIO-TEMPORAL DISCOVERY ENDPOINTS
# YOUR CORE VISION - REAL-TIME OPPORTUNITY DISCOVERY
# ==========================================

@app.post("/ai/discover/live-opportunities")
async def discover_live_opportunities(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """
    ðŸŽ¯ CORE FEATURE: Discover live opportunities in your immediate vicinity
    Solves: "I'm sitting here but don't know what's happening around me"
    """
    try:
        if not ai_engine.spatio_temporal:
            return {
                "success": True,
                "message": "Spatio-temporal discovery demo mode",
                "demo_opportunities": [
                    {
                        "title": "Emergency Plumber Available Now",
                        "category": "Individual & Home Services",
                        "business": "QuickFix Plumbing",
                        "distance": "200m away",
                        "offer": "No extra charges for emergency call",
                        "urgency": "ðŸ”¥ Available for next 2 hours",
                        "contact": "+91-9999999999"
                    },
                    {
                        "title": "Happy Hour Started - 50% Off Drinks", 
                        "category": "Food & Beverages",
                        "business": "SkyLounge Bar",
                        "distance": "150m away", 
                        "offer": "50% off all drinks until 7 PM",
                        "urgency": "ðŸš¨ Ending in 3 hours",
                        "contact": "+91-8888888888"
                    }
                ]
            }
        
        # Get user location and context
        location = request.get("location", {"lat": 12.9716, "lon": 77.5946})  # Default to Bangalore
        user_preferences = request.get("preferences", [])
        radius_km = request.get("radius_km", 2.0)  # Default 2km radius
        
        # Create user context
        user_context = UserContext(
            user_id=request.get("user_id", "anonymous"),
            current_location=location,
            current_time=datetime.now(),
            day_of_week=datetime.now().strftime("%A"),
            time_of_day=ai_engine.spatio_temporal._get_time_of_day(datetime.now()),
            weather=None,
            user_behavior_pattern={},
            recent_searches=request.get("recent_searches", []),
            preferences=user_preferences,
            budget_range=request.get("budget_range", {"min": 0, "max": 10000})
        )
        
        # Get context-aware recommendations
        recommendations = await ai_engine.spatio_temporal.get_context_aware_recommendations(user_context)
        
        return {
            "success": True,
            "message": "Live opportunities discovered in your vicinity",
            "your_location": f"ðŸ“ {location}",
            "search_radius": f"{radius_km}km",
            "current_context": recommendations["current_context"],
            "live_opportunities": recommendations["live_opportunities"],
            "insights": recommendations["context_insights"],
            "predictions": recommendations["behavioral_predictions"],
            "summary": {
                "total_found": recommendations["total_opportunities"],
                "urgent_opportunities": recommendations["urgent_count"],
                "categories_available": recommendations["categories_available"]
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Live opportunity discovery error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/discover/new-place-guide") 
async def new_place_guide(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """
    ðŸ—ºï¸ NEW PLACE INTELLIGENCE: Complete guide when you're in a new city/place
    Solves: "I'm in a new place and don't know anything about it"
    """
    try:
        # Simple debug check first
        logger.info(f"New place guide called with request: {request}")
        
        # Safely extract data with type checking
        location = request.get("location", "Unknown Location")
        user_preferences = request.get("user_preferences", {})
        
        # Handle location format
        if isinstance(location, str):
            city_name = location
            location_coords = {"lat": 12.9716, "lon": 77.5946}  # Default coordinates
        elif isinstance(location, dict):
            city_name = request.get("city_name", location.get("city", "Unknown City"))
            location_coords = location
        else:
            city_name = "Unknown City"
            location_coords = {"lat": 12.9716, "lon": 77.5946}
        
        # Extract user interests safely
        if isinstance(user_preferences, dict):
            user_interests = user_preferences.get("interests", ["food", "entertainment", "shopping"])
        else:
            user_interests = ["food", "entertainment", "shopping"]
        
        duration_days = request.get("duration_days", 1)
        
        if not ai_engine.spatio_temporal:
            return {
                "success": True,
                "message": f"New place guide for {city_name}",
                "city": city_name,
                "location_info": {
                    "city": city_name,
                    "coordinates": location_coords,
                    "local_time": datetime.now().strftime("%I:%M %p"),
                    "day": datetime.now().strftime("%A, %B %d, %Y")
                },
                "essential_info": {
                    "must_visit": [f"{city_name} City Center", "Local Market", "Famous Restaurant"],
                    "transport": ["Metro available", "Auto-rickshaws common", "Ola/Uber active"],
                    "safety": ["Generally safe", "Avoid late night travel alone"],
                    "local_tips": ["Bargain at markets", "Try local cuisine", "Use local apps"],
                    "user_interests": user_interests
                },
                "timestamp": datetime.now().isoformat()
            }
        
        # Create user context for new place - with error handling
        try:
            user_context = UserContext(
                user_id=request.get("user_id", "traveler"),
                current_location=location_coords,
                current_time=datetime.now(),
                day_of_week=datetime.now().strftime("%A"),
                time_of_day=ai_engine.spatio_temporal._get_time_of_day(datetime.now()) if ai_engine.spatio_temporal else "day",
                weather=None,
                user_behavior_pattern={"new_visitor": True},
                recent_searches=[],
                preferences=user_interests,
                budget_range=request.get("budget_range", {"min": 0, "max": 5000})
            )
        except Exception as ctx_error:
            logger.error(f"UserContext creation failed: {ctx_error}")
            # Return simplified response if UserContext fails
            return {
                "success": True,
                "message": f"New place guide for {city_name} (simplified mode)",
                "city": city_name,
                "location_info": {
                    "city": city_name,
                    "coordinates": location_coords,
                    "local_time": datetime.now().strftime("%I:%M %p")
                },
                "user_interests": user_interests,
                "recommendations": ["Explore local attractions", "Try local cuisine", "Use public transport"],
                "timestamp": datetime.now().isoformat()
            }
        
        # Get comprehensive new place recommendations
        recommendations = await ai_engine.spatio_temporal.get_context_aware_recommendations(user_context)
        
        # Group opportunities by category for new visitor
        categorized_opportunities = {}
        for opp in recommendations["live_opportunities"]:
            category = opp.get("category", "Other")
            if category not in categorized_opportunities:
                categorized_opportunities[category] = []
            categorized_opportunities[category].append(opp)
        
        return {
            "success": True,
            "message": f"Complete guide for {city_name}",
            "location_info": {
                "city": city_name,
                "coordinates": location,
                "local_time": datetime.now().strftime("%I:%M %p"),
                "day": datetime.now().strftime("%A, %B %d, %Y")
            },
            "immediate_opportunities": recommendations["live_opportunities"][:5],
            "categorized_guide": categorized_opportunities,
            "new_visitor_tips": [
                f"ðŸ• {recommendations['current_context']['time']} - Perfect timing for exploring",
                "ðŸ“± Save emergency contacts and local transport apps",
                "ðŸ’° Keep both cash and cards handy",
                "ðŸ—ºï¸ Download offline maps for the area",
                f"â­ {len(recommendations['live_opportunities'])} opportunities available right now"
            ],
            "duration_planning": {
                "suggested_duration": f"{duration_days} day(s)",
                "must_do_today": recommendations["live_opportunities"][:3],
                "plan_ahead": "Check tomorrow's events and bookings"
            },
            "local_insights": recommendations["context_insights"],
            "total_discoveries": len(recommendations["live_opportunities"]),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"New place guide error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/discover/time-sensitive-alerts")
async def time_sensitive_alerts(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """
    â° TIME-SENSITIVE OPPORTUNITIES: Urgent deals and offers ending soon
    Solves: "Missing time-limited opportunities and flash deals"
    """
    try:
        location = request.get("location", {"lat": 12.9716, "lon": 77.5946})
        alert_types = request.get("alert_types", ["flash_deals", "happy_hours", "last_minute", "emergency_services"])
        urgency_threshold = request.get("urgency_threshold", 0.7)  # 70% urgency minimum
        
        if not ai_engine.spatio_temporal:
            return {
                "success": True,
                "message": "Time-sensitive alerts demo mode",
                "urgent_alerts": [
                    {
                        "type": "flash_deal",
                        "title": "Electronics Store - 30% Off Laptops",
                        "urgency": "ðŸš¨ Ending in 2 hours",
                        "savings": "Save up to â‚¹15,000",
                        "action": "Visit store before 8 PM"
                    },
                    {
                        "type": "happy_hour",
                        "title": "Rooftop Bar Happy Hour",
                        "urgency": "ðŸ”¥ Started 30 minutes ago",
                        "savings": "50% off all drinks",
                        "action": "Book table now"
                    }
                ]
            }
        
        # Create user context
        user_context = UserContext(
            user_id=request.get("user_id", "urgent_user"),
            current_location=location,
            current_time=datetime.now(),
            day_of_week=datetime.now().strftime("%A"),
            time_of_day=ai_engine.spatio_temporal._get_time_of_day(datetime.now()),
            weather=None,
            user_behavior_pattern={"urgency_sensitive": True},
            recent_searches=[],
            preferences=alert_types,
            budget_range=request.get("budget_range", {"min": 0, "max": 10000})
        )
        
        # Get opportunities and filter for urgency
        all_opportunities = await ai_engine.spatio_temporal.discover_live_opportunities(user_context, 3.0)
        urgent_opportunities = [
            opp for opp in all_opportunities 
            if opp.urgency_score >= urgency_threshold or opp.time_sensitive
        ]
        
        # Categorize alerts
        alerts_by_type = {
            "ending_very_soon": [],  # < 1 hour
            "ending_soon": [],       # 1-3 hours  
            "today_only": [],        # < 24 hours
            "emergency_available": []  # Emergency services
        }
        
        current_time = datetime.now()
        for opp in urgent_opportunities:
            time_remaining = opp.valid_until - current_time
            
            if time_remaining < timedelta(hours=1):
                alerts_by_type["ending_very_soon"].append(opp)
            elif time_remaining < timedelta(hours=3):
                alerts_by_type["ending_soon"].append(opp)
            elif time_remaining < timedelta(hours=24):
                alerts_by_type["today_only"].append(opp)
            
            if "emergency" in opp.title.lower() or "plumber" in opp.title.lower():
                alerts_by_type["emergency_available"].append(opp)
        
        return {
            "success": True,
            "message": "Time-sensitive alerts for your location",
            "alert_summary": {
                "total_urgent": len(urgent_opportunities),
                "ending_very_soon": len(alerts_by_type["ending_very_soon"]),
                "ending_soon": len(alerts_by_type["ending_soon"]),
                "today_only": len(alerts_by_type["today_only"]),
                "emergency_services": len(alerts_by_type["emergency_available"])
            },
            "priority_alerts": [
                {
                    "alert_level": "ðŸš¨ CRITICAL - Ending in < 1 hour",
                    "opportunities": [
                        {
                            "title": opp.title,
                            "business": opp.business_name,
                            "offer": opp.current_offer,
                            "time_left": str(opp.valid_until - current_time),
                            "distance": f"{int(opp.distance_meters)}m",
                            "action": "BOOK NOW" if opp.booking_required else "GO NOW",
                            "contact": opp.contact_info
                        } for opp in alerts_by_type["ending_very_soon"]
                    ]
                },
                {
                    "alert_level": "âš ï¸ URGENT - Ending in 1-3 hours", 
                    "opportunities": [
                        {
                            "title": opp.title,
                            "business": opp.business_name,
                            "offer": opp.current_offer,
                            "time_left": str(opp.valid_until - current_time),
                            "distance": f"{int(opp.distance_meters)}m",
                            "savings": f"â‚¹{int(opp.original_price - opp.discounted_price)}",
                            "contact": opp.contact_info
                        } for opp in alerts_by_type["ending_soon"]
                    ]
                }
            ],
            "emergency_services": [
                {
                    "title": opp.title,
                    "business": opp.business_name,
                    "distance": f"{int(opp.distance_meters)}m",
                    "availability": "Available now",
                    "contact": opp.contact_info["phone"]
                } for opp in alerts_by_type["emergency_available"]
            ],
            "location": location,
            "urgency_threshold": urgency_threshold,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Time-sensitive alerts error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/discover/virtual-events")
async def discover_virtual_events(
    request: dict = Body(...),
    api_key: str = Depends(validate_api_key)
):
    """
    ðŸ’» VIRTUAL EVENTS & ONLINE SERVICES: Discover live online opportunities
    Includes: Webinars, online lectures, virtual workshops, coding bootcamps, etc.
    """
    try:
        user_interests = request.get("interests", ["education", "technology", "business"])
        event_types = request.get("event_types", ["webinars", "workshops", "lectures", "training"])
        urgency_filter = request.get("urgency_filter", 0.5)  # Minimum urgency score
        
        if not ai_engine.spatio_temporal:
            return {
                "success": True,
                "message": "Virtual events demo mode",
                "demo_events": [
                    {
                        "title": "Live Coding Bootcamp - Python Programming",
                        "category": "Virtual Events & Online Services",
                        "type": "coding_bootcamp",
                        "provider": "TechMaster Academy",
                        "starting_in": "30 minutes",
                        "offer": "50% off today only",
                        "original_price": "â‚¹2,000",
                        "discounted_price": "â‚¹1,000",
                        "urgency": "ðŸš¨ Starting soon!",
                        "join_link": "https://zoom.us/join/123456"
                    },
                    {
                        "title": "Investment Masterclass - Live Q&A",
                        "category": "Virtual Events & Online Services", 
                        "type": "webinar",
                        "provider": "WealthBuilder Institute",
                        "starting_in": "2 hours",
                        "offer": "Free session - limited seats",
                        "original_price": "â‚¹500",
                        "discounted_price": "Free",
                        "urgency": "â° Limited seats",
                        "join_link": "https://meet.google.com/abc-def-ghi"
                    }
                ]
            }
        
        # Create user context for virtual events
        user_context = UserContext(
            user_id=request.get("user_id", "virtual_user"),
            current_location={"lat": 0.0, "lon": 0.0},  # Virtual events don't need location
            current_time=datetime.now(),
            day_of_week=datetime.now().strftime("%A"),
            time_of_day=ai_engine.spatio_temporal._get_time_of_day(datetime.now()),
            weather=None,
            user_behavior_pattern={"prefers_online": True},
            recent_searches=[],
            preferences=user_interests + event_types,
            budget_range=request.get("budget_range", {"min": 0, "max": 5000})
        )
        
        # Get all opportunities and filter for virtual events
        all_opportunities = await ai_engine.spatio_temporal.discover_live_opportunities(user_context, 999999)  # No distance limit for virtual
        virtual_opportunities = [
            opp for opp in all_opportunities 
            if opp.category == "Virtual Events & Online Services" and opp.urgency_score >= urgency_filter
        ]
        
        # Group by subcategory
        categorized_events = {}
        for opp in virtual_opportunities:
            subcategory = opp.subcategory
            if subcategory not in categorized_events:
                categorized_events[subcategory] = []
            categorized_events[subcategory].append(opp)
        
        # Format virtual events response
        formatted_events = []
        current_time = datetime.now()
        
        for opp in virtual_opportunities:
            time_remaining = opp.valid_until - current_time
            
            formatted_event = {
                "event_id": opp.opportunity_id,
                "title": opp.title,
                "category": opp.category,
                "subcategory": opp.subcategory,
                "provider": opp.business_name,
                "description": opp.description,
                "offer": opp.current_offer,
                "pricing": {
                    "original_price": f"â‚¹{int(opp.original_price)}",
                    "discounted_price": f"â‚¹{int(opp.discounted_price)}",
                    "savings": f"â‚¹{int(opp.original_price - opp.discounted_price)}",
                    "discount_percentage": f"{opp.discount_percentage}%"
                },
                "timing": {
                    "time_remaining": str(time_remaining),
                    "valid_until": opp.valid_until.strftime("%I:%M %p"),
                    "urgency_score": opp.urgency_score,
                    "urgency_level": "ðŸš¨ Critical" if opp.urgency_score > 0.9 else "âš ï¸ Urgent" if opp.urgency_score > 0.7 else "â° Soon"
                },
                "access": {
                    "booking_required": opp.booking_required,
                    "availability": opp.availability,
                    "join_method": "Video call/Online platform",
                    "contact": opp.contact_info
                },
                "benefits": [
                    "Join from anywhere - no travel needed",
                    "Interactive live session with Q&A",
                    "Recording available for later access",
                    "Digital certificate upon completion"
                ]
            }
            formatted_events.append(formatted_event)
        
        return {
            "success": True,
            "message": "Virtual events and online services available now",
            "summary": {
                "total_virtual_events": len(virtual_opportunities),
                "urgent_events": len([e for e in virtual_opportunities if e.urgency_score > 0.8]),
                "free_events": len([e for e in virtual_opportunities if e.discounted_price == 0]),
                "categories_available": list(categorized_events.keys())
            },
            "current_context": {
                "time": datetime.now().strftime("%I:%M %p"),
                "day": datetime.now().strftime("%A, %B %d, %Y"),
                "optimal_for": "Online learning and virtual networking"
            },
            "virtual_events": formatted_events,
            "categorized_events": categorized_events,
            "advantages": [
                "ðŸ  Join from home - no commute needed",
                "ðŸ’° Often cheaper than in-person events",
                "ðŸŒ Access global experts and content",
                "ðŸ“¹ Usually recorded for later viewing",
                "âš¡ Instant access - book and join immediately"
            ],
            "urgency_filter": urgency_filter,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Virtual events discovery error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    print("ðŸš€ Starting IBCM AI Service - UNIVERSAL INTELLIGENCE")
    print(f"ðŸ¦™ Model: {config.LLAMA_MODEL}")
    print(f"ðŸ”§ Device: {config.DEVICE}")
    print(f"ðŸ“¡ Service: http://{config.API_HOST}:{config.API_PORT}")
    print(f"ðŸ”‘ API Key: {config.API_KEY}")
    print("ðŸŒ UNIVERSAL AI: Financial, Healthcare, Education, Business, Lifestyle, and more!")
    print("ðŸ›ï¸ REAL-TIME STOCK EXCHANGE: Live pricing, flash deals, price tracking")
    
    # Verify all endpoints are registered
    print(f"ðŸ“Š Total Endpoints: {len(app.routes)} routes")
    
    uvicorn.run(app, host=config.API_HOST, port=config.API_PORT)